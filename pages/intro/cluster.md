---
title: 集群使用指南
---

# 集群使用指南

[[toc]]

![天河](/cluster/tianhe.png)

## 超算集群介绍

### 什么是超级计算机？

“超算”即“超级计算”或“超级计算机”（Supercomputing / Supercomputer），是专为处理大规模、高性能科学计算任务而设计的计算平台。它们通常具备远超普通计算设备的算力，广泛应用于气象模拟、分子动力学、基因组学分析等对计算资源要求极高的领域。

传统上，超级计算机的性能以每秒浮点运算次数（FLOPS）为主要衡量标准。然而，随着计算需求的多样化与可持续发展的重视，单一的 FLOPS 指标已不再全面，业界也逐渐引入了包括存储访问速度、能效比（如碳排放水平）等多维度的评估指标。

目前，全球最具权威性的超级计算机性能排名是 [Top500 榜单](https://www.top500.org/lists/top500/)。我国的「神威」与「天河」等系统曾多次上榜，而我校自研的「太乙」集群也曾于 2018 年入选该榜单，位列第 127 位，展现出强劲的自主计算能力。

### 超级计算机用来解决什么问题？

超级计算机最初的诞生是为了解决那些对计算能力要求极高、数据规模庞大、求解过程极其复杂的科学与工程问题。随着计算技术的不断演进，超级计算机也经历了从同构集群向异构集群的架构转型，逐步在多个领域发挥出越来越广泛和深远的作用。

按笔者的理解，超级计算机的典型应用场景主要可以归纳为以下三个方向：

1. 科学研究类问题
    - 🌀 气候与气象模拟
    - 🧬 分子模拟与药物设计
    - 🧫 基因组学与生命科学
    - 🌌 天体物理与宇宙模拟
    - 🔐 密码破解与安全通信
2. 人工智能与大数据
    - 🧠 深度学习训练
    - 🗺 图神经网络与复杂系统建模
3. 量子计算机
    - ⚛ 量子计算机目前仍然没有自己的存储系统，通常来说量子计算机的构建目前仍然需要依托超算平台

因此，学习和使用超级计算机并非计算机专业学生的“专利”。它对来自不同学科背景、具有多样研究问题的科研人员同样开放与重要。例如，我校陈晓非教授课题组于 2017 年凭借“非线性地震模拟”项目，荣获高性能计算领域最具影响力的[“戈登·贝尔奖”](https://ess.sustech.edu.cn/New-detail-id-105.html)，该项目正是建立在超级计算平台之上的跨学科研究典范。

### 超级计算机 101

超级计算机，说白了就是一台**超大号、超快版**的计算机。它不是我们日常用的笔记本或台式机，而是由成百上千颗高性能处理器、海量存储设备和高速网络连接组合在一起的庞大系统。

从硬件角度来看，你可以把它理解成三大部分：
   - 🧠 **计算单元**：也就是一堆非常强的“芯片”或“处理器”。它们可以是多核 CPU、高性能 GPU，甚至是更专业的加速器（比如 AI 芯片），专门用来同时做很多复杂的计算。
   - 💾 **存储系统**：类似“超级硬盘”，用来保存你要处理的大量数据，比如天气模型、分子结构、图像数据等。超级计算的数据可能是以 TB、PB 甚至更高为单位的。
   - 🌐 **高速网络**：这些芯片和存储设备不是靠“插根网线”就能连在一起的，它们之间需要靠一种非常快的“通信高速公路”来交换数据，速度比普通家用网络快成千上万倍。

但光有硬件是不够的，想让这么庞大复杂的系统正常运转，还需要一整套软件系统来协调调度：
   - 🧭 **操作系统**：就像超级计算机的大脑，负责管理各个部分，保证它们可以互相配合（比如 Linux）。
   - 🛠️ **并行编程环境**：要让几千个计算核心“同时干活”，我们得用一些专门的工具和方法来告诉它们怎么分工协作，比如 MPI、OpenMP、CUDA 等。这就像一支上千人的施工队，每个人要知道自己的任务。
   - 📋 **作业调度系统**：每个用户提交的计算任务都要排队分配资源，谁先做、在哪做、做多久，全靠调度系统来安排。常见的调度系统有 Slurm、PBS 等。（后面会详细讲）

### 使用超级计算机我需要掌握什么？

想要上手使用超级计算机，不需要你一开始就是顶级程序员，但掌握一些基本技能是非常必要的。下面是你需要了解的几个关键方面：

1. **远程访问超级计算机：`ssh`**

   > 超级计算机通常部署在机房或数据中心，用户需要通过远程登录的方式访问它。你需要学会使用 `ssh` 命令，从自己的电脑连接到超算服务器，就像“连线”进入另一个计算世界。

2. **Linux 基本指令与 Shell 脚本编写**

   > 超级计算机大多运行的是 Linux 系统，所以你需要了解一些基础命令，比如 `ls`（查看文件）、`cd`（切换目录）、`cp`（复制文件）等。此外，写一两个简单的 Shell 脚本，可以帮助你自动化提交任务、批量处理数据，提高效率。

3. **环境管理与配置**

   > 不同的程序、库和依赖会存在不同版本，为了让你的代码能在超算上顺利运行，你需要学会使用环境管理工具（如 `module`、`conda`、`venv` 等）来配置运行环境。

4. **使用作业管理系统**

   > 超算资源是多人共享的，不能像自己电脑一样随意运行程序。你需要将任务写成“作业脚本”，提交给调度系统（如 Slurm），让系统根据资源情况安排运行。掌握如何写作业脚本、查看队列、监控状态是关键技能。

5. **编程技能：高性能优化的奇技淫巧【进阶】**

   > 如果你希望充分发挥超算的威力，你可以进一步学习并行编程（如 MPI、OpenMP、CUDA）、算法优化、向量化编程等技巧，提升程序运行效率，让它“飞”起来。


::: info ✅ 小贴士
初学者不必一步到位，只要掌握前四项，就已经可以在超算平台上顺利运行自己的程序了！后续可以根据项目需要，逐步深入高性能优化的世界
:::

> [!IMPORTANT] 📑 学习资料
> 这些基础内容的学习，笔者推荐可以参考MIT的线上课程：[计算机教育中缺失的一课](https://missing-semester-cn.github.io/)，会带你至少Cover前三个最基本的内容，如果觉得课程内容过多，希望能够亲自上手实践，笔者推荐各位可以前往 [超算习堂](https://www.easyhpc.net/lab)，并在实训环境中锻炼自己的基础技能

### 超级计算机的常见配置

通常来说，超级计算机的配置会分为：登录节点、计算节点和存储节点，有的对应管理员还会设置专门的管理节点，不同的超级计算机集群的架构都不同，提前阅读超级计算机集群的结构会让你更清楚你有什么资源可以调用，评估是否满足自己的运算需求。不同节点的节点配置会略有不同：

| 节点类型         | 主要作用             | 常见配置特点                                             | 用户是否可直接使用          |
| ------------ | ---------------- | -------------------------------------------------- | ------------------ |
| **登录节点**     | 用户登录入口、任务准备与提交   | - 少量高频 CPU<br>- 适度内存<br>- 多用户共享<br>- 安装常用软件工具      | ✅ 是，通常通过 `ssh` 登录  |
| **计算节点**     | 实际执行计算任务         | - 高性能多核 CPU / GPU<br>- 大内存<br>- 支持并行计算<br>- 无图形界面  | 🚫 否，通过作业系统调度访问    |
| **存储节点**     | 负责读写与管理大规模数据     | - 大容量磁盘阵列<br>- 高速 I/O 接口（如 InfiniBand）<br>- 数据备份机制 | 🚫 否，由系统统一管理，不直接登录 |
| **管理节点（可选）** | 管理任务调度、资源分配、监控系统 | - 运行作业调度器（如 Slurm）<br>- 控制集群资源调度与运行状态              | 🚫 否，管理员专用         |

![集群设置](/cluster/cluster.png)

::: info ✅ 补充说明
1. 🧩 登录节点 ≠ 计算节点：你在登录节点上做准备工作（如代码编译、作业提交），而真正的计算会被作业调度系统分配到计算节点上执行。通常来说，在自己的用户目录下，登录节点和计算节点的路径会保持一致，但是具体的环境会有所不同，在配置环境时要注意是否能否兼容计算节点的配置。
2. 💾 存储节点一般与用户的工作目录**挂载**在一起，支持高并发访问，适合存储输入/输出数据、临时文件或结果文件。
:::

## 作业调度系统

在超级计算机上，资源总是有限的，而用户和任务却可能成百上千。这时，**作业调度系统**（Job Scheduler）就成为整个高性能计算平台的“总指挥官”，它负责接收用户任务、评估资源情况，并高效地将任务安排到适当的计算节点上执行。

### 调度系统是用来？

作业调度系统的核心价值在于**资源的高效利用与公平分配**。在没有调度系统的情况下，用户可能会争抢资源、任务冲突频发，最终导致计算资源被大量浪费或长时间闲置。而有了调度系统之后，它可以：

- 保证每个任务按规则排队执行（先来先服务、优先级、高通量等）
- 支持任务并行、分布式执行
- 合理预估资源占用，防止系统过载
- 自动记录任务状态与日志，便于用户跟踪与管理

### 常见的调度器系统

目前主流的调度器有：

* **Slurm**（Simple Linux Utility for Resource Management）：目前使用最广泛的开源调度系统，广泛用于高校、科研机构与国家超算中心
* **PBS / Torque**：较早的调度系统之一，许多老牌集群仍在使用
* **LSF、LoadLeveler、HTCondor** 等：多用于企业、商业场景或特定科研机构，启明和太乙使用的便是LSF作业调度系统

其中 **Slurm** 以其模块化、可扩展、文档完善的特点，在学术界和工程界都有非常高的采用率。

### Slurm 使用流程

本次校内超算竞赛平台采用的调度系统为Slurm，Slurm的官方指南请查看[这里](https://slurm.schedmd.com/quickstart.html)，我们在这里将会简单介绍Slurm的使用方式，Slurm的常用指令有：

| 命令             | 中文说明                                                                                                                     |
| -------------- | ------------------------------------------------------------------------------------------------------------------------ |
| **`sacct`**    | 用于查询作业或作业步骤的账务信息，包括正在运行或已完成的作业。                                                                                          |
| **`salloc`**   | 用于**实时分配资源**给一个作业。通常用于分配资源后启动一个交互式 Shell，用户可以在这个 Shell 中使用 `srun` 启动并行任务。                                                |
| **`sattach`**  | 用于**连接到一个正在运行的作业或作业步骤**，附加标准输入、输出、错误流以及信号处理功能。可多次连接或断开。                                                                  |
| **`sbatch`**   | 用于**提交一个作业脚本**以便稍后执行。脚本通常会包含一个或多个 `srun` 命令来启动并行任务。                                                                      |
| **`scancel`**  | 用于**取消一个等待中或正在运行的作业或作业步骤**。也可以用于向作业相关进程发送特定信号。                                                                           |
| **`sinfo`**    | 用于**查看 Slurm 管理的分区（partition）和节点状态**。支持多种过滤、排序和格式化选项。                                                                    |
| **`squeue`**   | 用于**查看作业或作业步骤的状态**。支持多种筛选、排序和格式化选项。默认按照优先级显示运行中的作业，然后是等待中的作业。                                                            |
| **`srun`**     | 用于**立即提交一个作业或启动作业步骤**。支持大量资源指定选项，包括：最小/最大节点数、CPU 数量、指定使用或排除的节点、节点特性（内存大小、磁盘空间、功能标签等）。一个作业可以包含多个串行或并行的作业步骤，分别在共享或独立资源上运行。 |

通常来说，我们会选择在登录撰写作业脚本 `job.slurm` 并通过 `sbatch` 将作业提交到对应的队列中，可以使用的队列可以通过 `sinfo` 来查看，下面是一个提交到CPU队列的Slurm脚本案例：

```bash
#!/bin/bash
#SBATCH --job-name=cpu_job_test       # 作业名称
#SBATCH --partition=cpu              # 提交到 CPU 队列（partition 名）
#SBATCH --nodes=1                    # 所需节点数
#SBATCH --ntasks=1                   # 总任务数（通常 = 核心数）
#SBATCH --cpus-per-task=4            # 每个任务使用的 CPU 核心数
#SBATCH --time=02:00:00              # 最长运行时间（格式：hh:mm:ss）
#SBATCH --output=cpu_job_%j.out      # 标准输出日志（%j 会替换为作业ID）
#SBATCH --error=cpu_job_%j.err       # 标准错误日志

# 加载所需的模块（根据你平台的 module 系统）
module purge
module load gcc/9.3.0
module load python/3.10

# 或者通过设置环境变量来配置环境
export PATH=$PATH:/work/user/bin
export LIBRARY_PATH=$LIBRARY_PATH:/work/user/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/work/user/lib

# 显示环境信息
echo "Job started on $(hostname) at $(date)"
echo "Running on CPU with $SLURM_CPUS_ON_NODE cores"

# 执行你的程序（示例为 Python 脚本）
python my_cpu_program.py

echo "Job finished at $(date)"
```

## 太乙与启明

## 参考

1. [超级计算机技术架构](https://chaosuanwiki.com/liaojiechaosuan/chao-ji-ji-suan-ji-ji-shu-jia-gou.html)
2. [超算平台入门教程 —— 简介](https://zhuanlan.zhihu.com/p/659384116)
3. [什么是超级计算？](https://www.ibm.com/cn-zh/topics/supercomputing)
4. [Slurm 用户使用手册](https://slurm.schedmd.com/quickstart.html)